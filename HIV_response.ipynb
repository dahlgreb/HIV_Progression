{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HIV_response.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcdFNL5UIlJt"
      },
      "source": [
        "# !pip install plotly\n",
        "\n",
        "# import plotly.express as px"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmvUm80TH-MO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmrZgK77h3gU"
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JylPppL1IdLw"
      },
      "source": [
        "# pd.options.plotting.backend = \"plotly\""
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51MxreETJNTZ"
      },
      "source": [
        "df_train = pd.read_csv('training_data.csv')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1UzIc5vV7Kc",
        "outputId": "0362da50-f60c-42ab-e3a8-ced29fe1409a"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['PatientID', 'Resp', 'PR Seq', 'RT Seq', 'VL-t0', 'CD4-t0'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UKy-_6UeJTze",
        "outputId": "c4eda838-f8e1-4610-f531-ad6bedc0ecc6"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PatientID</th>\n",
              "      <th>Resp</th>\n",
              "      <th>PR Seq</th>\n",
              "      <th>RT Seq</th>\n",
              "      <th>VL-t0</th>\n",
              "      <th>CD4-t0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCCCAATAAGGATAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAGCTAAAGCCAGGAA...</td>\n",
              "      <td>4.30</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGATAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>3.60</td>\n",
              "      <td>224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGGTAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>3.20</td>\n",
              "      <td>1017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAGGATAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>5.70</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAGTAAAGATAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>3.50</td>\n",
              "      <td>572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>996</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CCCATTAGTCCTATTGARACTGTACCAGTAMAATTAAAGCCAGGAA...</td>\n",
              "      <td>3.15</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>997</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CCCATYAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>5.50</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>998</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CCCATYAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>4.10</td>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CCTATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>3.37</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CCTATTAGTCCTATTGAAACTGTACCTGTAAAATTAAAGCMAGGAA...</td>\n",
              "      <td>4.97</td>\n",
              "      <td>570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PatientID  Resp  ... VL-t0 CD4-t0\n",
              "0            1     0  ...  4.30    145\n",
              "1            2     0  ...  3.60    224\n",
              "2            3     0  ...  3.20   1017\n",
              "3            4     0  ...  5.70    206\n",
              "4            5     0  ...  3.50    572\n",
              "..         ...   ...  ...   ...    ...\n",
              "995        996     0  ...  3.15    354\n",
              "996        997     0  ...  5.50     50\n",
              "997        998     0  ...  4.10    369\n",
              "998        999     0  ...  3.37    127\n",
              "999       1000     0  ...  4.97    570\n",
              "\n",
              "[1000 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gvCB729tuW-"
      },
      "source": [
        "feature = 'RT Seq'"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW38pdWHkCHS"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAmczEGPtr6i",
        "outputId": "3591f51e-4dcc-4071-a3b8-23bf442a9ec2"
      },
      "source": [
        "df_train['Resp'].value_counts()\n",
        "# strongly weighted towards 0"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    794\n",
              "1    206\n",
              "Name: Resp, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J3EvtEvJVMu"
      },
      "source": [
        "# df_train.plot.scatter(x='CD4-t0', y='VL-t0')"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfX6w8KVacav",
        "outputId": "b672c2c4-ece5-4fce-8441-a9174d35a485"
      },
      "source": [
        "df_train[feature].apply(lambda x: len(str(x))).value_counts()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "900     150\n",
              "909      93\n",
              "903      88\n",
              "1005     80\n",
              "750      74\n",
              "       ... \n",
              "1482      1\n",
              "1479      1\n",
              "951       1\n",
              "963       1\n",
              "1032      1\n",
              "Name: RT Seq, Length: 116, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkxlSdpxbdYf"
      },
      "source": [
        "# align_dynamic2(s1,s2)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqQG7D5lK_ut",
        "outputId": "c4ff8f05-de80-430b-c366-3881b9c64cfb"
      },
      "source": [
        "len(df_train[feature][0])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1005"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-uAdfA7Lrk3",
        "outputId": "9fecc25f-d1b6-4604-9f8a-c0a1f0fd4f6a"
      },
      "source": [
        "seq = df_train[feature][0]\n",
        "d = {}\n",
        "unique = 0\n",
        "for c in seq:\n",
        "  if c not in d:\n",
        "    d[c] = unique\n",
        "    unique += 1\n",
        "d"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 1, 'C': 0, 'G': 3, 'K': 8, 'M': 6, 'R': 7, 'T': 2, 'W': 5, 'Y': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oYA4DahXMaWA",
        "outputId": "9b0bada0-7013-4288-82ed-b9f9817dec4d"
      },
      "source": [
        "df_arr = pd.DataFrame()\n",
        "arr = []\n",
        "for k in d:\n",
        "  s = []\n",
        "  for c in seq:\n",
        "    if c == k:\n",
        "      s.append(1)\n",
        "    else:\n",
        "      s.append(0)\n",
        "  arr.append(s)\n",
        "  df_arr[k] = s\n",
        "df_arr"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>A</th>\n",
              "      <th>T</th>\n",
              "      <th>G</th>\n",
              "      <th>Y</th>\n",
              "      <th>W</th>\n",
              "      <th>M</th>\n",
              "      <th>R</th>\n",
              "      <th>K</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1005 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      C  A  T  G  Y  W  M  R  K\n",
              "0     1  0  0  0  0  0  0  0  0\n",
              "1     1  0  0  0  0  0  0  0  0\n",
              "2     1  0  0  0  0  0  0  0  0\n",
              "3     0  1  0  0  0  0  0  0  0\n",
              "4     0  0  1  0  0  0  0  0  0\n",
              "...  .. .. .. .. .. .. .. .. ..\n",
              "1000  0  1  0  0  0  0  0  0  0\n",
              "1001  0  1  0  0  0  0  0  0  0\n",
              "1002  0  0  0  1  0  0  0  0  0\n",
              "1003  0  0  0  1  0  0  0  0  0\n",
              "1004  1  0  0  0  0  0  0  0  0\n",
              "\n",
              "[1005 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS7Kxidl7NZ9",
        "outputId": "b495c664-95ad-49a3-fcf7-98e6b68e4970"
      },
      "source": [
        "df_arr.sum()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C    167\n",
              "A    402\n",
              "T    218\n",
              "G    210\n",
              "Y      4\n",
              "W      1\n",
              "M      1\n",
              "R      1\n",
              "K      1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcShvrgsPZmo"
      },
      "source": [
        "# R: G or A\n",
        "# Y: C or T\n",
        "def encode(seq,d,length):\n",
        "    arr = []\n",
        "    for k in d:\n",
        "      s = []\n",
        "      for c in seq:\n",
        "          if c == k:\n",
        "              s.append(1)\n",
        "          else:\n",
        "              s.append(0)\n",
        "      res = [0] * (length - len(s))\n",
        "      s.extend(res)\n",
        "      arr.append(s)\n",
        "    return np.array(arr)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtiASjRZQ_j3"
      },
      "source": [
        "df_train.dropna(inplace=True)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE9Nfc2PPg6S",
        "outputId": "d750344c-7c3b-43d1-bd0b-bd35f17e3762"
      },
      "source": [
        "# get the longest sequence length\n",
        "length = max(df_train[feature].apply(lambda x : len(x)))\n",
        "# one-hot encode each sequence\n",
        "encoded = []\n",
        "for seq in df_train[feature]:\n",
        "  encoded.append(encode(seq,d,length))\n",
        "np.shape(encoded)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(920, 9, 1482)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoLDosi2RMVS"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(encoded, np.array(df_train['Resp']), test_size=0.20)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX1ALbM7Tlrp",
        "outputId": "41ef62bf-2108-45d1-edb3-a836aacf854a"
      },
      "source": [
        "np.array(X_train[0])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fn-NjzHaqiN",
        "outputId": "7a6bccc7-7aec-428d-8a69-6b00835cb897"
      },
      "source": [
        "pd.Series(y_train).value_counts()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    594\n",
              "1    142\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPbwuzX_a26y"
      },
      "source": [
        "# upsampled_x=[]\n",
        "# upsampled_y=[]\n",
        "# for i,d in enumerate(X_train):\n",
        "#     upsampled.append(d)\n",
        "#     if y_train[i]==1:\n",
        "        "
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwphA_Tgi38r",
        "outputId": "f05893dd-ca36-4ea6-8f8b-a64d7266e887"
      },
      "source": [
        "np.shape(X_train), np.shape(y_train)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((736, 9, 1482), (736,))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwK2SZCHpFEV",
        "outputId": "ed6a9e89-624c-47f6-fb6e-e4c72df487ac"
      },
      "source": [
        "np.shape(X_test), np.shape(y_test)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((184, 9, 1482), (184,))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UziHF-8kpitQ"
      },
      "source": [
        "X_train = np.reshape(X_train,(736,9,1482,1))\n",
        "X_test = np.reshape(X_test,(184,9,1482,1))"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzgMe9VZPC4j",
        "outputId": "e2e35cbc-1b29-46b1-d89d-2341caaa8eb3"
      },
      "source": [
        "input_shape = (np.shape(X_train)[1],np.shape(X_train)[2],1)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu',padding='same', input_shape=input_shape))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, kernel_size=3, padding='same',activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "batch_size = 64\n",
        "num_epoch = 30\n",
        "#model training\n",
        "model_log = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=num_epoch,\n",
        "          verbose=1,\n",
        "          validation_data = (X_test,y_test),\n",
        "        #   class_weight={0:1, 1:2}\n",
        "          )"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 4s 314ms/step - loss: 2.2738 - accuracy: 0.6889 - val_loss: 0.6612 - val_accuracy: 0.7554\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 4s 294ms/step - loss: 0.4941 - accuracy: 0.8071 - val_loss: 0.5437 - val_accuracy: 0.7554\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 4s 295ms/step - loss: 0.4478 - accuracy: 0.8166 - val_loss: 0.5792 - val_accuracy: 0.7554\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 4s 294ms/step - loss: 0.4325 - accuracy: 0.8207 - val_loss: 0.5427 - val_accuracy: 0.7554\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.4328 - accuracy: 0.8234 - val_loss: 0.5600 - val_accuracy: 0.7554\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.4218 - accuracy: 0.8234 - val_loss: 0.5444 - val_accuracy: 0.7554\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 4s 294ms/step - loss: 0.4189 - accuracy: 0.8247 - val_loss: 0.5711 - val_accuracy: 0.7554\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 4s 292ms/step - loss: 0.4127 - accuracy: 0.8288 - val_loss: 0.5394 - val_accuracy: 0.7554\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.4067 - accuracy: 0.8329 - val_loss: 0.5431 - val_accuracy: 0.7609\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 3s 292ms/step - loss: 0.3839 - accuracy: 0.8315 - val_loss: 0.5553 - val_accuracy: 0.7609\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.3609 - accuracy: 0.8533 - val_loss: 0.5560 - val_accuracy: 0.7609\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.3211 - accuracy: 0.8641 - val_loss: 0.5423 - val_accuracy: 0.7554\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 3s 292ms/step - loss: 0.2779 - accuracy: 0.8954 - val_loss: 0.5981 - val_accuracy: 0.7554\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 4s 294ms/step - loss: 0.2052 - accuracy: 0.9198 - val_loss: 0.5769 - val_accuracy: 0.7337\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 4s 294ms/step - loss: 0.1599 - accuracy: 0.9511 - val_loss: 0.6549 - val_accuracy: 0.6576\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.1493 - accuracy: 0.9470 - val_loss: 0.7043 - val_accuracy: 0.7337\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.1018 - accuracy: 0.9755 - val_loss: 0.7645 - val_accuracy: 0.7174\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.0589 - accuracy: 0.9891 - val_loss: 0.7915 - val_accuracy: 0.7011\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 3s 292ms/step - loss: 0.0436 - accuracy: 0.9932 - val_loss: 1.0308 - val_accuracy: 0.7228\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.0308 - accuracy: 0.9946 - val_loss: 1.0213 - val_accuracy: 0.7174\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.0606 - val_accuracy: 0.7228\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.0156 - accuracy: 0.9986 - val_loss: 1.0522 - val_accuracy: 0.7011\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 4s 294ms/step - loss: 0.0169 - accuracy: 0.9986 - val_loss: 1.3416 - val_accuracy: 0.7120\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 4s 302ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.2456 - val_accuracy: 0.7120\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2876 - val_accuracy: 0.7011\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 4s 295ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2744 - val_accuracy: 0.7065\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 4s 295ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.4120 - val_accuracy: 0.7065\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 4s 292ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.7228\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4139 - val_accuracy: 0.7065\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 4s 293ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4109 - val_accuracy: 0.7120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_log.history\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('CNN model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "FmRO1h4rvLW2",
        "outputId": "478e8dee-7aec-4945-99b3-06e54b141d9d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74tnGhjeSXmx",
        "outputId": "eb004da6-b096-49e3-edf8-d94d591be0c7"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = list(map(lambda x: int(x>0.5), y_pred))\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7119565217391305"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAI87ma9nezx",
        "outputId": "975d18bb-82c9-4877-9754-5fea0c7fdea6"
      },
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[121,  18],\n",
              "       [ 35,  10]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UejCbkrmhvEo"
      },
      "source": [
        "#Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RREuLom8jeth",
        "outputId": "fb689e8c-5f8b-4574-8362-425e1b4d1ca8"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PatientID</th>\n",
              "      <th>Resp</th>\n",
              "      <th>PR Seq</th>\n",
              "      <th>RT Seq</th>\n",
              "      <th>VL-t0</th>\n",
              "      <th>CD4-t0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCCCAATAAGGATAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAGCTAAAGCCAGGAA...</td>\n",
              "      <td>4.3</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGATAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>3.6</td>\n",
              "      <td>224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGGTAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAGGATAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>5.7</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAGTAAAGATAG...</td>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PatientID  Resp  ... VL-t0 CD4-t0\n",
              "0          1     0  ...   4.3    145\n",
              "1          2     0  ...   3.6    224\n",
              "2          3     0  ...   3.2   1017\n",
              "3          4     0  ...   5.7    206\n",
              "4          5     0  ...   3.5    572\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy2AhtvlX_9d"
      },
      "source": [
        "df_train.dropna(subset=[feature],inplace=True)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCSH-MekXg2R"
      },
      "source": [
        "all_seq = ''\n",
        "for prseq in df_train[feature]:\n",
        "    all_seq+=str(prseq)\n",
        "char_index = list(set(all_seq))"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efZCZ9Nom3Hu"
      },
      "source": [
        "char_to_int = dict((c, i) for i, c in enumerate(char_index))"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNCxwFnIn4gF"
      },
      "source": [
        "max_len = df_train[feature].apply(lambda x: len(str(x))).max()"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a320GrU3peB7",
        "outputId": "f7691f14-06a0-4547-fc0d-05a7c41a7e51"
      },
      "source": [
        "char_to_int"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 10,\n",
              " 'B': 3,\n",
              " 'C': 0,\n",
              " 'D': 12,\n",
              " 'G': 9,\n",
              " 'H': 11,\n",
              " 'K': 2,\n",
              " 'M': 8,\n",
              " 'N': 4,\n",
              " 'R': 7,\n",
              " 'S': 5,\n",
              " 'T': 1,\n",
              " 'V': 14,\n",
              " 'W': 13,\n",
              " 'Y': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKvKvR2wmzwn"
      },
      "source": [
        "def encode_sequence_list(seqs,max_len):\n",
        "    out =''\n",
        "    encoded_seqs = []\n",
        "    for seq in seqs:\n",
        "        encoded_seq = [char_to_int[c] for c in seq]\n",
        "        encoded_seqs.append(encoded_seq)\n",
        "    return pad_sequences(encoded_seqs, padding='post')\n",
        "def decode_sequence_list(seqs):\n",
        "    decoded_seqs = []\n",
        "    for seq in seqs:\n",
        "        decoded_seq = [int_to_char[i] for i in seq]\n",
        "        decoded_seqs.append(decoded_seq)\n",
        "    return decoded_seqs"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWroKu7dkUQo"
      },
      "source": [
        "encoded_seqs = encode_sequence_list(df_train[feature],max_len)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYdzZlFgY1Ui",
        "outputId": "728380e4-f5fc-4580-a259-683da516d6ec"
      },
      "source": [
        "encoded_seqs.shape"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(920, 1482)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdyeVIWfYsvQ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_seqs = scaler.fit_transform(encoded_seqs)\n",
        "#Create a test and train sets of our data\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_seqs, np.array(df_train['Resp']), test_size=0.20)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lG_EfafaDYr"
      },
      "source": [
        "input_dim = X_train.shape[1] # the # features\n",
        "encoding_dim = 8 # first layer\n",
        "hidden_dim = int(encoding_dim / 2) #hidden layer\n",
        "\n",
        "nb_epoch = 250\n",
        "batch_size = 64\n",
        "learning_rate = 0.1"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1V1NQHnYbbr"
      },
      "source": [
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
        "decoder = Dense(encoding_dim, activation='relu')(encoder)\n",
        "decoder = Dense(input_dim, activation='tanh')(decoder)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U_T2QDmafEh"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', \n",
        "                    loss='mean_squared_error', \n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"model_seqs2.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOk91H5uhzzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5fc67e-7676-4f2f-e388-99eb3457cd60"
      },
      "source": [
        "history = autoencoder.fit(X_train, X_train,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_test, X_test),\n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpointer, tensorboard]).history"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "12/12 [==============================] - 1s 27ms/step - loss: 0.3327 - accuracy: 0.0000e+00 - val_loss: 0.3148 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2871 - accuracy: 0.0000e+00 - val_loss: 0.2615 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2346 - accuracy: 0.0000e+00 - val_loss: 0.2095 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1849 - accuracy: 0.0000e+00 - val_loss: 0.1628 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1086 - accuracy: 0.0000e+00 - val_loss: 0.0978 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0858 - accuracy: 0.0000e+00 - val_loss: 0.0804 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0716 - accuracy: 0.0000e+00 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0632 - accuracy: 0.0000e+00 - val_loss: 0.0638 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0584 - accuracy: 0.0000e+00 - val_loss: 0.0604 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0555 - accuracy: 0.0000e+00 - val_loss: 0.0581 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0536 - accuracy: 0.0000e+00 - val_loss: 0.0568 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0524 - accuracy: 0.0000e+00 - val_loss: 0.0557 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0515 - accuracy: 0.0000e+00 - val_loss: 0.0550 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0509 - accuracy: 0.0000e+00 - val_loss: 0.0547 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0505 - accuracy: 0.0000e+00 - val_loss: 0.0541 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0501 - accuracy: 0.0000e+00 - val_loss: 0.0538 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0499 - accuracy: 0.0000e+00 - val_loss: 0.0536 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0497 - accuracy: 0.0000e+00 - val_loss: 0.0533 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0495 - accuracy: 0.0000e+00 - val_loss: 0.0534 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0494 - accuracy: 0.0000e+00 - val_loss: 0.0530 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0492 - accuracy: 0.0000e+00 - val_loss: 0.0531 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0491 - accuracy: 0.0000e+00 - val_loss: 0.0528 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0489 - accuracy: 0.0000e+00 - val_loss: 0.0528 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0489 - accuracy: 0.0000e+00 - val_loss: 0.0527 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0488 - accuracy: 0.0000e+00 - val_loss: 0.0526 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.0000e+00 - val_loss: 0.0526 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0487 - accuracy: 0.0000e+00 - val_loss: 0.0525 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0486 - accuracy: 0.0000e+00 - val_loss: 0.0522 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0483 - accuracy: 0.0000e+00 - val_loss: 0.0511 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0469 - accuracy: 0.0000e+00 - val_loss: 0.0500 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0463 - accuracy: 0.0000e+00 - val_loss: 0.0497 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0460 - accuracy: 0.0000e+00 - val_loss: 0.0492 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0456 - accuracy: 0.0000e+00 - val_loss: 0.0488 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0452 - accuracy: 0.0000e+00 - val_loss: 0.0480 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0444 - accuracy: 0.0000e+00 - val_loss: 0.0470 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0435 - accuracy: 0.0000e+00 - val_loss: 0.0461 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0427 - accuracy: 0.0000e+00 - val_loss: 0.0448 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0411 - accuracy: 0.0000e+00 - val_loss: 0.0420 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0379 - accuracy: 0.0000e+00 - val_loss: 0.0385 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0348 - accuracy: 0.0000e+00 - val_loss: 0.0349 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.0000e+00 - val_loss: 0.0311 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0282 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0225 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0216 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0208 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0202 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.0000e+00 - val_loss: 0.0196 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0188 - accuracy: 0.0000e+00 - val_loss: 0.0190 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.0000e+00 - val_loss: 0.0184 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.0000e+00 - val_loss: 0.0179 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.0173 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.0000e+00 - val_loss: 0.0163 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.0000e+00 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.0000e+00 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.0000e+00 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.0000e+00 - val_loss: 0.0148 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0144 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0142 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0134 - accuracy: 0.0000e+00 - val_loss: 0.0139 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/250\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/250\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_xBpA9CLaGYS",
        "outputId": "cdb6a362-ea1d-48ea-f5b7-2e5829f8ea63"
      },
      "source": [
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('Autoencoder model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right');"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxzOu_w6dvai"
      },
      "source": [
        "prseq = df_train[[feature,'Resp']]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuEnON6bc1Bz",
        "outputId": "393c4a6c-2254-4e26-eafa-3bfd29933978"
      },
      "source": [
        "#encode all the data\n",
        "encoded_seqs = encode_sequence_list(prseq[feature],297)\n",
        "#scale it\n",
        "scaled_data = MinMaxScaler().fit_transform(encoded_seqs)\n",
        "#predict it\n",
        "predicted = autoencoder.predict(scaled_data)\n",
        "#get the error term\n",
        "mse = np.mean(np.power(scaled_data - predicted, 2), axis=1)\n",
        "#now add them to our data frame\n",
        "prseq['MSE'] = mse"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ebv8EArod2g-",
        "outputId": "f4ad40e6-0c82-4bed-ed08-60a96070cf43"
      },
      "source": [
        "prseq"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RT Seq</th>\n",
              "      <th>Resp</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAGCTAAAGCCAGGAA...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.009538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAACCAGGAA...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAACCAGGAA...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.005483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>CCCATTAGTCCTATTAAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAACCGGGAA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.004824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>CCCATTAGTCCTATTGARACTGTACCAGTAAAATTAAASCCAGGAA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010589</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>920 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                RT Seq  Resp       MSE\n",
              "0    CCCATTAGTCCTATTGAAACTGTACCAGTAAAGCTAAAGCCAGGAA...     0  0.004934\n",
              "1    CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...     0  0.004722\n",
              "2    CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...     0  0.003537\n",
              "3    CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...     0  0.009538\n",
              "4    CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...     0  0.003682\n",
              "..                                                 ...   ...       ...\n",
              "915  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAACCAGGAA...     0  0.006178\n",
              "916  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAACCAGGAA...     0  0.005483\n",
              "917  CCCATTAGTCCTATTAAAACTGTACCAGTAAAATTAAAGCCAGGAA...     0  0.011560\n",
              "918  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAACCGGGAA...     1  0.004824\n",
              "919  CCCATTAGTCCTATTGARACTGTACCAGTAAAATTAAASCCAGGAA...     1  0.010589\n",
              "\n",
              "[920 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fltWnzSreKFH",
        "outputId": "700ab797-d596-44a6-deeb-1fc5c57b5f5b"
      },
      "source": [
        "prseq.groupby('Resp')['MSE'].median()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resp\n",
              "0    0.005565\n",
              "1    0.007337\n",
              "Name: MSE, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXESQUhnsS2v"
      },
      "source": [
        "predicted = autoencoder.predict(X_test)\n",
        "#get the error term\n",
        "mse = np.mean(np.power(X_test - predicted, 2), axis=1)\n",
        "#now add them to our data frame\n",
        "y_pred = mse > 0.004"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3F9xqGXqlPn",
        "outputId": "2488015d-1f97-4834-e90b-2cafe5aa60eb"
      },
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 35, 107],\n",
              "       [  3,  39]])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DpPpPAN07Wx",
        "outputId": "fa96e8f4-d5b6-485c-c934-4471445d8690"
      },
      "source": [
        "(95+31)/len(y_test)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6847826086956522"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNlHrptlfKKs"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6eTsQjCgETV",
        "outputId": "c93ba2ec-027a-4df5-fad4-528c2cc484af"
      },
      "source": [
        "pip install XGBoost"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: XGBoost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from XGBoost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from XGBoost) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1FKUN_KgGMm"
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmugiYUX7HHF"
      },
      "source": [
        "df_train.dropna(inplace=True)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilqJEgy08UG5"
      },
      "source": [
        "def splitpad(txt,padlen):\n",
        "    out=[]\n",
        "    for c in txt:\n",
        "        out.append(c)\n",
        "    out.extend([0]*padlen-len(out))\n",
        "    return out"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yonExIII7Ihd"
      },
      "source": [
        "pr_seq = pd.DataFrame()\n",
        "for i in range(length):\n",
        "    pr_seq[i] = df_train[feature]"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbxMMlC26yLu"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(scaled_seqs, np.array(df_train['Resp']), test_size=0.20)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymd_K5p7gI6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5aad6f-6351-42a2-c2cb-88526d5bd17d"
      },
      "source": [
        "xgb_classifier = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)\n",
        "xgb_classifier.fit(X_train,y_train)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(alpha=10, max_depth=5, n_estimators=10)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ9jDrjV6xIS"
      },
      "source": [
        "y_pred = xgb_classifier.predict(X_test)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H07MuviKtDP4",
        "outputId": "7d7abb38-909a-42fc-a8f3-742b23ff94cb"
      },
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[140,   4],\n",
              "       [ 29,  11]])"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OROYASXg9J_j"
      },
      "source": [
        "#explore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnQ_ZSaJMeAM"
      },
      "source": [
        "from pdb import set_trace"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0azYjYjkOmC5",
        "outputId": "b2016059-bf3d-46fd-f8a1-f1e0f21a8123"
      },
      "source": [
        "!pip install XGBoost\n",
        "import xgboost as xgb"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: XGBoost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from XGBoost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from XGBoost) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umRTKIhd9LH-"
      },
      "source": [
        "def splitpad(txt,padlen):\n",
        "    out = []\n",
        "    for c in txt:\n",
        "        out.append(c)\n",
        "    out.extend([0]*(padlen-len(out)))\n",
        "    return out"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGzbKokZM27Y"
      },
      "source": [
        "df_train.dropna(subset=[feature],inplace=True)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jACU0Z8XUKr_"
      },
      "source": [
        "# get the longest sequence length\n",
        "length = max(df_train[feature].apply(lambda x : len(x)))"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujl9fGdA9Vm1"
      },
      "source": [
        "seqs = np.array([splitpad(seq,length) for seq in df_train[feature]])"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "d_rtMKD29nPo",
        "outputId": "921f8a40-6b2b-4487-e7a7-c6e6df7f8a3f"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "for i in range(length):\n",
        "    df[i] = seqs[:,i]\n",
        "df['resp'] = df_train['Resp']\n",
        "df.head()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1443</th>\n",
              "      <th>1444</th>\n",
              "      <th>1445</th>\n",
              "      <th>1446</th>\n",
              "      <th>1447</th>\n",
              "      <th>1448</th>\n",
              "      <th>1449</th>\n",
              "      <th>1450</th>\n",
              "      <th>1451</th>\n",
              "      <th>1452</th>\n",
              "      <th>1453</th>\n",
              "      <th>1454</th>\n",
              "      <th>1455</th>\n",
              "      <th>1456</th>\n",
              "      <th>1457</th>\n",
              "      <th>1458</th>\n",
              "      <th>1459</th>\n",
              "      <th>1460</th>\n",
              "      <th>1461</th>\n",
              "      <th>1462</th>\n",
              "      <th>1463</th>\n",
              "      <th>1464</th>\n",
              "      <th>1465</th>\n",
              "      <th>1466</th>\n",
              "      <th>1467</th>\n",
              "      <th>1468</th>\n",
              "      <th>1469</th>\n",
              "      <th>1470</th>\n",
              "      <th>1471</th>\n",
              "      <th>1472</th>\n",
              "      <th>1473</th>\n",
              "      <th>1474</th>\n",
              "      <th>1475</th>\n",
              "      <th>1476</th>\n",
              "      <th>1477</th>\n",
              "      <th>1478</th>\n",
              "      <th>1479</th>\n",
              "      <th>1480</th>\n",
              "      <th>1481</th>\n",
              "      <th>resp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 1483 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  ... 1474 1475 1476 1477 1478 1479 1480 1481 resp\n",
              "0  C  C  C  A  T  T  A  G  T  ...    0    0    0    0    0    0    0    0    0\n",
              "1  C  C  C  A  T  T  A  G  T  ...    0    0    0    0    0    0    0    0    0\n",
              "2  C  C  C  A  T  T  A  G  T  ...    0    0    0    0    0    0    0    0    0\n",
              "3  C  C  C  A  T  T  A  G  T  ...    0    0    0    0    0    0    0    0    0\n",
              "4  C  C  C  A  T  T  A  G  T  ...    0    0    0    0    0    0    0    0    0\n",
              "\n",
              "[5 rows x 1483 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ_DTCWMS6gV"
      },
      "source": [
        "all_codes = []\n",
        "for i in range(length):\n",
        "    all_codes.extend(df[i].unique())\n",
        "all_codes = pd.Series(all_codes).unique()\n",
        "all_codes = dict(zip(all_codes,range(len(all_codes))))\n",
        "df_code=pd.DataFrame()\n",
        "for i in range(length):\n",
        "    df_code[i] = df[i].apply(lambda x: all_codes[x])"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nO5sPCl-nFh"
      },
      "source": [
        "# get the average value at each index in the sequence\n",
        "avg_seq = []\n",
        "for i in range(length):\n",
        "    avg_seq.append(df[i].mode().item())"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHpZCFoOBx-u"
      },
      "source": [
        "df_diff=pd.DataFrame()\n",
        "for i in range(length):\n",
        "    df_diff[i] = df[i]!=avg_seq[i]\n",
        "    # df_diff[i] = (df[i]!=avg_seq[i])/(df[i]!=avg_seq[i]).sum"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqu-oD2iSCnx"
      },
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(df_code, df['resp'], test_size=0.30)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y70sOgcMOYjl"
      },
      "source": [
        "# df_diff\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df_diff, df['resp'], test_size=0.30)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uvXW49IVv5l"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_train[['VL-t0','CD4-t0']], df_train['Resp'], test_size=0.20)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlkKb6YHO3ak"
      },
      "source": [
        "xgb_classifier = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10,scale_pos_weight=1)\n",
        "xgb_classifier.fit(X_train,y_train)\n",
        "preds = xgb_classifier.predict(X_test)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py08Q9G0PRA9",
        "outputId": "0b552dc1-514a-4c9b-c8f4-18973e549ba2"
      },
      "source": [
        "confusion_matrix(y_test, preds)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[136,   7],\n",
              "       [ 30,  11]])"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkrnRtsDQDs4"
      },
      "source": [
        "feature = 'PR Seq'"
      ],
      "execution_count": 154,
      "outputs": []
    }
  ]
}